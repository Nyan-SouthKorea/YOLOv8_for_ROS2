{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이썬 기본 패키지\n",
    "import threading\n",
    "import time\n",
    "from copy import deepcopy\n",
    "\n",
    "# 추가 설치 패키지\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "class Custom_YOLOv8:\n",
    "    def __init__(self, model_name='yolov8n.pt', filter=None):\n",
    "        '''\n",
    "        입력되는 Image와 Depth Map에서 사물인식하여, 감지된 사물의 결과의 x, y, depth 정보를 반환\n",
    "        \n",
    "        model_name : YOLOv8 model 이름 입력(yolov8n.pt, yolov8s.pt, yolov8m.pt, yolov8l.pt, yolov8x.pt, 혹은 custom model 입력)\n",
    "        filter : 감지를 원하는 특정 사물이 있을 경우 list형태로 입력. None일 경우 모두 추론(None or ['person', 'cat'])\n",
    "        '''\n",
    "        print('자세한 기능 사용법 안내: https://github.com/Nyan-SouthKorea/YOLOv8_for_ROS2')\n",
    "        self._check_cuda()\n",
    "        self.model = YOLO(model_name)\n",
    "        self.filter = filter\n",
    "        self.img = None\n",
    "        self.depth_map = None\n",
    "        self.dic_list = []\n",
    "        self.class_list = []\n",
    "\n",
    "\n",
    "    def run(self, img, depth_map, mode='multi', conf_thresh=0.65):\n",
    "        '''\n",
    "        이미지를 입력하는 순간 기존 구동되던 multi-thread로 인퍼런스 됨. 그렇기 때문에 가장 최근에 인식된 결과가 반환됨.\n",
    "        이미지 한장만 추론하는 목적으로는 적합하지 않다. 계속 들어오는 frame을 실시간으로 추론하는데 적합.\n",
    "        추론하기 원하는 image와 depth_map을 입력.\n",
    "        class 내부에서 multi-thread로 구동되는 YOLOv8 모델에 img와 depth_map을 업데이트하고 지금까지 처리된 가장 최근의 추론 결과를 반환.\n",
    "        (이렇게 처리하는 이유는, 성능이 낮은 컴퓨터에서도 렉이 걸리지 않게끔 보이기 위해서임)\n",
    "        \n",
    "        img : cv2로 처리할 수 있는 numpy 배열의 bgr 이미지\n",
    "        depth_map : numpy 배열의 2차원 1채널 거리 정보(안에 숫자들은 int, float 상관 없음)\n",
    "        mode : 'multi'와 'single'로 나뉨. multi는 thread 구동이고, single은 구동될 때 까지 기다려야 함\n",
    "        conf_thresh : confidence threshold 설정\n",
    "        '''\n",
    "\n",
    "        # 처리해야 하는 img, depth_map 업데이트\n",
    "        self.img = img\n",
    "        self.depth_map = depth_map\n",
    "        self.conf_thresh = conf_thresh\n",
    "\n",
    "        # 쓰레드 구동\n",
    "        \n",
    "        # multi vs single 조건\n",
    "        if mode == 'single':\n",
    "            thread.join() # 쓰레드가 끝날 때 까지 확실히 기다려서 최근 이미지에 대한 반환값을 제공한다\n",
    "        \n",
    "        # 가장 최근까지 처리된 추론 결과 반환\n",
    "        if self.dic_list == []:\n",
    "            return_value = False\n",
    "        else:\n",
    "            return_value = True\n",
    "        return return_value, self.dic_list\n",
    "    \n",
    "        '''\n",
    "        thread.is_alive() 기능으로 살아있는지 확인하고 multi-thread 구동하기\n",
    "        '''\n",
    "    \n",
    "    \n",
    "    def draw(self):\n",
    "        '''\n",
    "        내부 변수 self.img와 self.dic_list를 활용하여 그려서 결과 반환\n",
    "        '''\n",
    "        img = deepcopy(self.img)\n",
    "        dic_list = deepcopy(self.dic_list)\n",
    "        for dic in self.dic_list:\n",
    "            cv2.rectangle(img, (dic['bbox'][0], dic['bbox'][1]), (dic['bbox'][2], dic['bbox'][3]), (0,0,255), 2)\n",
    "            text = f'{dic[\"class_name\"]}:{round(dic[\"conf\"], 2)}, depth: {dic[\"depth\"]}'\n",
    "            cv2.putText(img, text, (dic['bbox'][0], dic['bbox'][1]+25), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "        return img\n",
    "    \n",
    "\n",
    "    def _predict(self):\n",
    "        '''\n",
    "        이미지를 추론하여 self 변수들에 결과를 업데이트함\n",
    "        '''\n",
    "        # 추론\n",
    "        results = self.model.predict(source = cv2.cvtColor(self.img, cv2.COLOR_BGR2RGB), verbose = False)[0]\n",
    "        if self.class_list == None:\n",
    "            self.class_list = results.names\n",
    "        results = results.boxes.data.tolist()\n",
    "        dic_list = []\n",
    "        for result in results:\n",
    "            x1, y1, x2, y2, conf, cls = int(result[0]), int(result[1]), int(result[2]), int(result[3]), round(float(result[4]), 2), int(result[5])\n",
    "            class_name = self.class_list[cls] # class이름 추출\n",
    "            # conf_thresh 넘는 경우만 계산\n",
    "            if conf < self.conf_thresh:\n",
    "                continue\n",
    "\n",
    "            # 만약 filter를 설정해 놓았을 경우, 원하는 class만 감지하기\n",
    "            if self.filter != None:\n",
    "                if not class_name in self.filter:\n",
    "                    continue\n",
    "\n",
    "            # 감지된 사물의 x, y 포인트 계산\n",
    "            center_x = int((x2+x1)/2)\n",
    "            center_y = int((y2+y1)/2)\n",
    "            # depth 계산\n",
    "            depth = self._get_depth(depth_map, [x1,y1,x2,y2]) # depth 추출\n",
    "            dic_list.append({'bbox':[x1, y1, x2, y2], 'conf':conf, \n",
    "                                'class_name':class_name, 'center_x':center_x, 'center_y':center_y, 'depth':depth})\n",
    "        # 실시간 추론값 업데이트\n",
    "        self.dic_list = deepcopy(dic_list)\n",
    "        \n",
    "\n",
    "    # 삭제 예정\n",
    "    def _prediction_thread(self):\n",
    "        '''\n",
    "        run 함수에서 업데이트된 self.img와 self.depth_map을 multi-thread로 처리하여 추론 결과를 self.dic_list에 업데이트 함\n",
    "        '''\n",
    "        class_list = None\n",
    "        while True:\n",
    "            # 종료 조건\n",
    "            if self.stop_request == True:\n",
    "                break\n",
    "\n",
    "            # run()에서 이미지를 투입할 때 마다 구동\n",
    "            if self.run_request == False:\n",
    "                time.sleep(0.01)\n",
    "                continue\n",
    "            self.run_request = False\n",
    "\n",
    "            # run()에서 투입된 정보가 로직이 실행되는 중간에 섞이지 않도록 내부 함수로 업데이트\n",
    "            img = deepcopy(self.img)\n",
    "            depth_map = deepcopy(self.depth_map)\n",
    "            conf_thresh = deepcopy(self.conf_thresh)\n",
    "\n",
    "            # 추론\n",
    "            results = self.model.predict(source = cv2.cvtColor(img, cv2.COLOR_BGR2RGB), verbose = False)[0]\n",
    "            if class_list == None:\n",
    "                class_list = results.names\n",
    "            results = results.boxes.data.tolist()\n",
    "            dic_list = []\n",
    "            for result in results:\n",
    "                x1, y1, x2, y2, conf, cls = int(result[0]), int(result[1]), int(result[2]), int(result[3]), round(float(result[4]), 2), int(result[5])\n",
    "                class_name = class_list[cls] # class이름 추출\n",
    "                # conf_thresh 넘는 경우만 계산\n",
    "                if conf < conf_thresh:\n",
    "                    continue\n",
    "\n",
    "                # 만약 filter를 설정해 놓았을 경우, 원하는 class만 감지하기\n",
    "                if self.filter != None:\n",
    "                    if not class_name in self.filter:\n",
    "                        continue\n",
    "\n",
    "                # 감지된 사물의 x, y 포인트 계산\n",
    "                center_x = int((x2+x1)/2)\n",
    "                center_y = int((y2+y1)/2)\n",
    "                # depth 계산\n",
    "                depth = self._get_depth(depth_map, [x1,y1,x2,y2]) # depth 추출\n",
    "                dic_list.append({'bbox':[x1, y1, x2, y2], 'conf':conf, \n",
    "                                 'class_name':class_name, 'center_x':center_x, 'center_y':center_y, 'depth':depth})\n",
    "            # 실시간 추론값 업데이트\n",
    "            self.dic_list = deepcopy(dic_list)\n",
    "\n",
    "    def _get_depth(self, depth_map, bbox, rate=0.3):\n",
    "        '''\n",
    "        depth_map에서 bbox영역의 중앙 영역 depth를 반환\n",
    "\n",
    "        depth_map : 내부 변수\n",
    "        bbox : 내부 변수\n",
    "        rate : bbox 면적에서 해당 rate만큼의 중앙 영역의 평균 값을 계산함\n",
    "        '''\n",
    "        # rate 반영한 bbox 계산\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        # bbox의 가로 세로 길이\n",
    "        x_len = x2-x1\n",
    "        y_len = y2-y1\n",
    "        # rate 반영한 bbox의 가로 세로 길이\n",
    "        new_x_len = x_len*rate\n",
    "        new_y_len = y_len*rate\n",
    "        # rate 반영된 bbox 수치 계산\n",
    "        new_x1 = x1 + ((x_len-new_x_len)/2)\n",
    "        new_y1 = y1 + ((y_len-new_y_len)/2)\n",
    "        new_x2 = x2 - ((x_len-new_x_len)/2)\n",
    "        new_y2 = y2 - ((y_len-new_y_len)/2)\n",
    "        new_x1, new_y1, new_x2, new_y2 = int(new_x1), int(new_y1), int(new_x2), int(new_y2)\n",
    "        # depth_map에서 원하는 부분 crop하여 평균 depth 구하기\n",
    "        crop_depth = depth_map[new_y1:new_y2, new_x1:new_x2]\n",
    "        mean_depth = np.mean(crop_depth)\n",
    "        return round(mean_depth, 2)\n",
    "    \n",
    "    def _check_cuda(self):\n",
    "        '''\n",
    "        현재 설치된 torch 환경이 YOLO를 GPU에서 구동할 수 있는 환경인지 검사\n",
    "        '''\n",
    "        if torch.cuda.is_available():\n",
    "            print('GPU 사용 가능')\n",
    "        else:\n",
    "            print('GPU 사용 불가. CPU를 통한 추론만 가능')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "자세한 기능 사용법 안내: https://github.com/Nyan-SouthKorea/YOLOv8_for_ROS2\n",
      "GPU 사용 가능\n",
      "감지 내역 없음\n",
      "[{'bbox': [260, 103, 347, 352], 'conf': 0.93, 'class_name': 'person', 'center_x': 303, 'center_y': 227, 'depth': 123.77}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nyan\\anaconda3\\envs\\yolo\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\nyan\\anaconda3\\envs\\yolo\\lib\\site-packages\\numpy\\core\\_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "from ros2_object_detection import Custom_YOLOv8\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "custom_YOLOv8 = Custom_YOLOv8(model_name='yolov8x.pt')\n",
    "\n",
    "path = 'test_img'\n",
    "img_list = os.listdir(path)\n",
    "for img_name in img_list:\n",
    "    # 이미지 읽기\n",
    "    img = cv2.imread(f'{path}/{img_name}')\n",
    "\n",
    "    # 더미 depth파일 생성\n",
    "    h, w, c = img.shape\n",
    "    depth_map = np.random.randint(0, 256, (w, h), dtype=np.uint8)\n",
    "\n",
    "    # 인퍼런스\n",
    "    ret, dic_list = custom_YOLOv8.run(img, depth_map)\n",
    "    if ret:\n",
    "        print(dic_list)\n",
    "    else:\n",
    "        print('감지 내역 없음')\n",
    "    draw_img = custom_YOLOv8.draw()\n",
    "\n",
    "    # 그리기\n",
    "    cv2.imshow('test', draw_img)\n",
    "    if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        custom_YOLOv8.stop()\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
