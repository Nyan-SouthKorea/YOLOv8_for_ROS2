{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현재 환경에서 YOLOv8을 GPU로 추론할 수 있는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 사용 가능\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print('GPU 사용 가능')\n",
    "else:\n",
    "    print('GPU 사용 불가. CPU를 통한 추론만 가능')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기본 필요 패키지 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트 이미지 로드해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['image_1.png', 'image_2.png']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이미지 경로 지정\n",
    "image_path = './test images'\n",
    "\n",
    "# 이미지 리스트 불러와보기\n",
    "image_name_list = os.listdir(image_path)\n",
    "image_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 표시해보기\n",
    "img_list = []\n",
    "for image_name in image_name_list:\n",
    "    # cv2로 이미지 불러오기\n",
    "    img = cv2.imread(f'{image_path}/{image_name}')\n",
    "    # 비율을 해치지 않고 리사이즈 하는 과정\n",
    "    h, w, c = img.shape\n",
    "    img = cv2.resize(img, (640, int(h/w*640)))\n",
    "    # 리스트에 이미지 저장(후추 YOLO 추론을 위함)\n",
    "    img_list.append(img)\n",
    "    # 이미지 표시하기\n",
    "    cv2.imshow('test image show', img)\n",
    "    cv2.waitKey(0) # 아무 키를 누르면 다음으로 넘어감\n",
    "# 코드가 끝난 뒤 이미지 창 닫아주기\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[182, 132,  43],\n",
       "        [177, 127,  39],\n",
       "        [175, 124,  37],\n",
       "        ...,\n",
       "        [104,  71,  44],\n",
       "        [105,  71,  44],\n",
       "        [105,  71,  44]],\n",
       "\n",
       "       [[191, 140,  45],\n",
       "        [189, 139,  46],\n",
       "        [186, 136,  43],\n",
       "        ...,\n",
       "        [106,  72,  44],\n",
       "        [106,  72,  44],\n",
       "        [106,  72,  44]],\n",
       "\n",
       "       [[198, 146,  49],\n",
       "        [198, 146,  48],\n",
       "        [197, 144,  46],\n",
       "        ...,\n",
       "        [107,  72,  43],\n",
       "        [107,  72,  45],\n",
       "        [107,  72,  45]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[134, 105,  55],\n",
       "        [134, 104,  57],\n",
       "        [134, 103,  56],\n",
       "        ...,\n",
       "        [193, 143,  49],\n",
       "        [192, 143,  48],\n",
       "        [192, 143,  47]],\n",
       "\n",
       "       [[134, 104,  55],\n",
       "        [134, 104,  55],\n",
       "        [133, 104,  54],\n",
       "        ...,\n",
       "        [193, 144,  51],\n",
       "        [193, 144,  50],\n",
       "        [191, 142,  46]],\n",
       "\n",
       "       [[133, 104,  54],\n",
       "        [133, 104,  54],\n",
       "        [133, 104,  54],\n",
       "        ...,\n",
       "        [193, 144,  51],\n",
       "        [193, 144,  50],\n",
       "        [193, 144,  49]]], dtype=uint8)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이미지가 어떻게 생겼는지 관찰하기\n",
    "img_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLOv8로 이미지 추론해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLO 모델 로드\n",
    "model_dic = {'n':'yolov8n.pt', \n",
    "             's':'yolov8s.pt', \n",
    "             'm':'yolov8m.pt', \n",
    "             'l': 'yolov8l.pt', \n",
    "             'x': 'yolov8x.pt', \n",
    "             '1080x': 'yolo'}\n",
    "model = YOLO(model_dic['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Results object with attributes:\n",
       "\n",
       "boxes: ultralytics.engine.results.Boxes object\n",
       "keypoints: None\n",
       "masks: None\n",
       "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
       "obb: None\n",
       "orig_img: array([[[ 43, 132, 182],\n",
       "        [ 39, 127, 177],\n",
       "        [ 37, 124, 175],\n",
       "        ...,\n",
       "        [ 44,  71, 104],\n",
       "        [ 44,  71, 105],\n",
       "        [ 44,  71, 105]],\n",
       "\n",
       "       [[ 45, 140, 191],\n",
       "        [ 46, 139, 189],\n",
       "        [ 43, 136, 186],\n",
       "        ...,\n",
       "        [ 44,  72, 106],\n",
       "        [ 44,  72, 106],\n",
       "        [ 44,  72, 106]],\n",
       "\n",
       "       [[ 49, 146, 198],\n",
       "        [ 48, 146, 198],\n",
       "        [ 46, 144, 197],\n",
       "        ...,\n",
       "        [ 43,  72, 107],\n",
       "        [ 45,  72, 107],\n",
       "        [ 45,  72, 107]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 55, 105, 134],\n",
       "        [ 57, 104, 134],\n",
       "        [ 56, 103, 134],\n",
       "        ...,\n",
       "        [ 49, 143, 193],\n",
       "        [ 48, 143, 192],\n",
       "        [ 47, 143, 192]],\n",
       "\n",
       "       [[ 55, 104, 134],\n",
       "        [ 55, 104, 134],\n",
       "        [ 54, 104, 133],\n",
       "        ...,\n",
       "        [ 51, 144, 193],\n",
       "        [ 50, 144, 193],\n",
       "        [ 46, 142, 191]],\n",
       "\n",
       "       [[ 54, 104, 133],\n",
       "        [ 54, 104, 133],\n",
       "        [ 54, 104, 133],\n",
       "        ...,\n",
       "        [ 51, 144, 193],\n",
       "        [ 50, 144, 193],\n",
       "        [ 49, 144, 193]]], dtype=uint8)\n",
       "orig_shape: (315, 640)\n",
       "path: 'image0.jpg'\n",
       "probs: None\n",
       "save_dir: None\n",
       "speed: {'preprocess': 0.0, 'inference': 58.86411666870117, 'postprocess': 0.0}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이미지 넣기\n",
    "test_img = img_list[0]\n",
    "result = model.predict(source = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB), verbose = False)[0]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'person',\n",
       " 1: 'bicycle',\n",
       " 2: 'car',\n",
       " 3: 'motorcycle',\n",
       " 4: 'airplane',\n",
       " 5: 'bus',\n",
       " 6: 'train',\n",
       " 7: 'truck',\n",
       " 8: 'boat',\n",
       " 9: 'traffic light',\n",
       " 10: 'fire hydrant',\n",
       " 11: 'stop sign',\n",
       " 12: 'parking meter',\n",
       " 13: 'bench',\n",
       " 14: 'bird',\n",
       " 15: 'cat',\n",
       " 16: 'dog',\n",
       " 17: 'horse',\n",
       " 18: 'sheep',\n",
       " 19: 'cow',\n",
       " 20: 'elephant',\n",
       " 21: 'bear',\n",
       " 22: 'zebra',\n",
       " 23: 'giraffe',\n",
       " 24: 'backpack',\n",
       " 25: 'umbrella',\n",
       " 26: 'handbag',\n",
       " 27: 'tie',\n",
       " 28: 'suitcase',\n",
       " 29: 'frisbee',\n",
       " 30: 'skis',\n",
       " 31: 'snowboard',\n",
       " 32: 'sports ball',\n",
       " 33: 'kite',\n",
       " 34: 'baseball bat',\n",
       " 35: 'baseball glove',\n",
       " 36: 'skateboard',\n",
       " 37: 'surfboard',\n",
       " 38: 'tennis racket',\n",
       " 39: 'bottle',\n",
       " 40: 'wine glass',\n",
       " 41: 'cup',\n",
       " 42: 'fork',\n",
       " 43: 'knife',\n",
       " 44: 'spoon',\n",
       " 45: 'bowl',\n",
       " 46: 'banana',\n",
       " 47: 'apple',\n",
       " 48: 'sandwich',\n",
       " 49: 'orange',\n",
       " 50: 'broccoli',\n",
       " 51: 'carrot',\n",
       " 52: 'hot dog',\n",
       " 53: 'pizza',\n",
       " 54: 'donut',\n",
       " 55: 'cake',\n",
       " 56: 'chair',\n",
       " 57: 'couch',\n",
       " 58: 'potted plant',\n",
       " 59: 'bed',\n",
       " 60: 'dining table',\n",
       " 61: 'toilet',\n",
       " 62: 'tv',\n",
       " 63: 'laptop',\n",
       " 64: 'mouse',\n",
       " 65: 'remote',\n",
       " 66: 'keyboard',\n",
       " 67: 'cell phone',\n",
       " 68: 'microwave',\n",
       " 69: 'oven',\n",
       " 70: 'toaster',\n",
       " 71: 'sink',\n",
       " 72: 'refrigerator',\n",
       " 73: 'book',\n",
       " 74: 'clock',\n",
       " 75: 'vase',\n",
       " 76: 'scissors',\n",
       " 77: 'teddy bear',\n",
       " 78: 'hair drier',\n",
       " 79: 'toothbrush'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pre-trained 모델의 class list 불러오기\n",
    "class_list = result.names\n",
    "class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[192.26681518554688,\n",
       "  128.29116821289062,\n",
       "  324.4732360839844,\n",
       "  313.5286560058594,\n",
       "  0.9254348874092102,\n",
       "  0.0],\n",
       " [432.61962890625,\n",
       "  83.29297637939453,\n",
       "  548.6654052734375,\n",
       "  273.46148681640625,\n",
       "  0.896065354347229,\n",
       "  0.0],\n",
       " [293.00469970703125,\n",
       "  119.42230987548828,\n",
       "  403.75701904296875,\n",
       "  227.19317626953125,\n",
       "  0.8083090782165527,\n",
       "  0.0],\n",
       " [157.49020385742188,\n",
       "  28.31103515625,\n",
       "  196.29910278320312,\n",
       "  85.83868408203125,\n",
       "  0.7552218437194824,\n",
       "  0.0],\n",
       " [10.61409854888916,\n",
       "  175.37918090820312,\n",
       "  39.07166290283203,\n",
       "  210.255126953125,\n",
       "  0.6687518358230591,\n",
       "  0.0],\n",
       " [426.3678894042969,\n",
       "  0.7651710510253906,\n",
       "  450.2699890136719,\n",
       "  55.111568450927734,\n",
       "  0.5911059379577637,\n",
       "  0.0],\n",
       " [128.76058959960938,\n",
       "  181.66921997070312,\n",
       "  176.75576782226562,\n",
       "  241.11984252929688,\n",
       "  0.5569432377815247,\n",
       "  0.0],\n",
       " [69.22067260742188,\n",
       "  160.48236083984375,\n",
       "  115.5289306640625,\n",
       "  243.58319091796875,\n",
       "  0.4555675685405731,\n",
       "  0.0],\n",
       " [178.72128295898438,\n",
       "  74.23811340332031,\n",
       "  196.29684448242188,\n",
       "  86.42842102050781,\n",
       "  0.3147118389606476,\n",
       "  36.0],\n",
       " [70.66148376464844,\n",
       "  160.7026824951172,\n",
       "  98.50190734863281,\n",
       "  190.04405212402344,\n",
       "  0.31433844566345215,\n",
       "  0.0],\n",
       " [587.7532958984375,\n",
       "  166.89498901367188,\n",
       "  625.5318603515625,\n",
       "  209.28720092773438,\n",
       "  0.28024429082870483,\n",
       "  0.0]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 우리가 원하는 형태로 후처리 하기(bbox와 class 이름)\n",
    "results = result.boxes.data.tolist()\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bbox': [192, 128, 324, 313], 'conf': 0.93, 'class_name': 'person'},\n",
       " {'bbox': [432, 83, 548, 273], 'conf': 0.9, 'class_name': 'person'},\n",
       " {'bbox': [293, 119, 403, 227], 'conf': 0.81, 'class_name': 'person'},\n",
       " {'bbox': [157, 28, 196, 85], 'conf': 0.76, 'class_name': 'person'},\n",
       " {'bbox': [10, 175, 39, 210], 'conf': 0.67, 'class_name': 'person'},\n",
       " {'bbox': [426, 0, 450, 55], 'conf': 0.59, 'class_name': 'person'},\n",
       " {'bbox': [128, 181, 176, 241], 'conf': 0.56, 'class_name': 'person'},\n",
       " {'bbox': [69, 160, 115, 243], 'conf': 0.46, 'class_name': 'person'},\n",
       " {'bbox': [178, 74, 196, 86], 'conf': 0.31, 'class_name': 'skateboard'},\n",
       " {'bbox': [70, 160, 98, 190], 'conf': 0.31, 'class_name': 'person'},\n",
       " {'bbox': [587, 166, 625, 209], 'conf': 0.28, 'class_name': 'person'}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dic_list에 이쁘게 변환해서 넣어보기\n",
    "dic_list = []\n",
    "for result in results:\n",
    "    x1, y1, x2, y2, conf, cls = int(result[0]), int(result[1]), int(result[2]), int(result[3]), round(float(result[4]), 2), int(result[5])\n",
    "    class_name = class_list[cls] # class이름 추출\n",
    "    dic_list.append({'bbox':[x1, y1, x2, y2], 'conf':conf, 'class_name':class_name})\n",
    "dic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 직접 이미지 위에 그림을 그려보기\n",
    "import copy\n",
    "img = copy.deepcopy(test_img)\n",
    "for dic in dic_list:\n",
    "    cv2.rectangle(img, (dic['bbox'][0], dic['bbox'][1]), (dic['bbox'][2], dic['bbox'][3]), (0,0,255), 1)\n",
    "    text = f'{dic[\"class_name\"]}:{round(dic[\"conf\"], 2)}'\n",
    "    cv2.putText(img, text, (dic['bbox'][0], dic['bbox'][1]+10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 1)\n",
    "cv2.imshow('draw image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전 과정을 자동화 해보기 + 이미지 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = './output'\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "for img_name in os.listdir(image_path):\n",
    "    img = cv2.imread(f'{image_path}/{img_name}')\n",
    "    h, w, c = img.shape\n",
    "    img = cv2.resize(img, (640, int(h/w*640)))\n",
    "    result = model.predict(source = cv2.cvtColor(img, cv2.COLOR_BGR2RGB), verbose = False)[0]\n",
    "    results = result.boxes.data.tolist()\n",
    "    dic_list = []\n",
    "    for result in results:\n",
    "        x1, y1, x2, y2, conf, cls = int(result[0]), int(result[1]), int(result[2]), int(result[3]), round(float(result[4]), 2), int(result[5])\n",
    "        class_name = class_list[cls] # class이름 추출\n",
    "        dic_list.append({'bbox':[x1, y1, x2, y2], 'conf':conf, 'class_name':class_name})\n",
    "    for dic in dic_list:\n",
    "        cv2.rectangle(img, (dic['bbox'][0], dic['bbox'][1]), (dic['bbox'][2], dic['bbox'][3]), (0,0,255), 1)\n",
    "        text = f'{dic[\"class_name\"]}:{round(dic[\"conf\"], 2)}'\n",
    "        cv2.putText(img, text, (dic['bbox'][0], dic['bbox'][1]+10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 1)\n",
    "    # 이미지 저장\n",
    "    cv2.imwrite(f'{output_path}/{img_name}', img)\n",
    "    cv2.imshow('draw image', img)\n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "source": [
    "웹캠 환경에서 실시간 추론 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "자세한 기능 사용법 안내: https://github.com/Nyan-SouthKorea/YOLOv8_for_ROS2\n",
      "GPU 사용 가능\n",
      "[{'bbox': [66, 78, 624, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 345, 'center_y': 278, 'depth': 127.71}]\n",
      "[{'bbox': [66, 79, 609, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 337, 'center_y': 279, 'depth': 127.22}]\n",
      "[{'bbox': [68, 80, 606, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 337, 'center_y': 279, 'depth': 127.56}]\n",
      "[{'bbox': [67, 79, 594, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 330, 'center_y': 279, 'depth': 127.05}]\n",
      "[{'bbox': [67, 77, 598, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 332, 'center_y': 278, 'depth': 127.71}]\n",
      "[{'bbox': [69, 77, 603, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 336, 'center_y': 278, 'depth': 127.24}]\n",
      "[{'bbox': [69, 77, 603, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 336, 'center_y': 278, 'depth': 127.36}]\n",
      "[{'bbox': [69, 77, 604, 479], 'conf': 0.89, 'class_name': 'person', 'center_x': 336, 'center_y': 278, 'depth': 127.76}]\n",
      "[{'bbox': [68, 76, 603, 479], 'conf': 0.89, 'class_name': 'person', 'center_x': 335, 'center_y': 277, 'depth': 126.97}]\n",
      "[{'bbox': [71, 76, 609, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 340, 'center_y': 277, 'depth': 127.16}]\n",
      "[{'bbox': [72, 76, 611, 479], 'conf': 0.89, 'class_name': 'person', 'center_x': 341, 'center_y': 277, 'depth': 127.47}]\n",
      "[{'bbox': [72, 76, 611, 479], 'conf': 0.89, 'class_name': 'person', 'center_x': 341, 'center_y': 277, 'depth': 127.47}]\n",
      "[{'bbox': [72, 78, 622, 479], 'conf': 0.89, 'class_name': 'person', 'center_x': 347, 'center_y': 278, 'depth': 127.24}]\n",
      "[{'bbox': [72, 78, 622, 479], 'conf': 0.89, 'class_name': 'person', 'center_x': 347, 'center_y': 278, 'depth': 127.24}]\n",
      "[{'bbox': [74, 83, 617, 479], 'conf': 0.89, 'class_name': 'person', 'center_x': 345, 'center_y': 281, 'depth': 127.7}]\n",
      "[{'bbox': [75, 77, 622, 479], 'conf': 0.89, 'class_name': 'person', 'center_x': 348, 'center_y': 278, 'depth': 128.13}]\n",
      "[{'bbox': [75, 77, 622, 479], 'conf': 0.89, 'class_name': 'person', 'center_x': 348, 'center_y': 278, 'depth': 128.13}]\n",
      "[{'bbox': [73, 78, 622, 479], 'conf': 0.89, 'class_name': 'person', 'center_x': 347, 'center_y': 278, 'depth': 126.65}]\n",
      "[{'bbox': [73, 78, 622, 479], 'conf': 0.89, 'class_name': 'person', 'center_x': 347, 'center_y': 278, 'depth': 126.65}]\n",
      "[{'bbox': [74, 85, 613, 479], 'conf': 0.89, 'class_name': 'person', 'center_x': 343, 'center_y': 282, 'depth': 127.71}]\n",
      "[{'bbox': [75, 81, 614, 479], 'conf': 0.89, 'class_name': 'person', 'center_x': 344, 'center_y': 280, 'depth': 126.62}]\n",
      "[{'bbox': [73, 79, 618, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 345, 'center_y': 279, 'depth': 128.49}]\n",
      "[{'bbox': [73, 79, 618, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 345, 'center_y': 279, 'depth': 128.49}]\n",
      "[{'bbox': [75, 76, 615, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 345, 'center_y': 277, 'depth': 127.51}]\n",
      "[{'bbox': [74, 73, 610, 479], 'conf': 0.89, 'class_name': 'person', 'center_x': 342, 'center_y': 276, 'depth': 127.97}]\n",
      "[{'bbox': [74, 75, 608, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 341, 'center_y': 277, 'depth': 127.56}]\n",
      "[{'bbox': [74, 75, 608, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 341, 'center_y': 277, 'depth': 127.56}]\n",
      "[{'bbox': [76, 77, 610, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 343, 'center_y': 278, 'depth': 126.72}]\n",
      "[{'bbox': [76, 76, 605, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 340, 'center_y': 277, 'depth': 127.38}]\n",
      "[{'bbox': [74, 77, 611, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 342, 'center_y': 278, 'depth': 127.2}]\n",
      "[{'bbox': [74, 77, 611, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 342, 'center_y': 278, 'depth': 127.2}]\n",
      "[{'bbox': [74, 77, 609, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 341, 'center_y': 278, 'depth': 127.64}]\n",
      "[{'bbox': [74, 77, 609, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 341, 'center_y': 278, 'depth': 127.64}]\n",
      "[{'bbox': [72, 78, 599, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 335, 'center_y': 278, 'depth': 127.96}]\n",
      "[{'bbox': [72, 78, 599, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 335, 'center_y': 278, 'depth': 127.96}]\n",
      "[{'bbox': [73, 78, 607, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 340, 'center_y': 278, 'depth': 127.62}]\n",
      "[{'bbox': [74, 79, 602, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 338, 'center_y': 279, 'depth': 126.32}]\n",
      "[{'bbox': [74, 79, 602, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 338, 'center_y': 279, 'depth': 126.32}]\n",
      "[{'bbox': [73, 76, 603, 479], 'conf': 0.89, 'class_name': 'person', 'center_x': 338, 'center_y': 277, 'depth': 126.62}]\n",
      "[{'bbox': [70, 75, 609, 479], 'conf': 0.88, 'class_name': 'person', 'center_x': 339, 'center_y': 277, 'depth': 127.51}]\n",
      "[{'bbox': [73, 76, 613, 479], 'conf': 0.88, 'class_name': 'person', 'center_x': 343, 'center_y': 277, 'depth': 127.91}]\n",
      "[{'bbox': [72, 94, 598, 479], 'conf': 0.88, 'class_name': 'person', 'center_x': 335, 'center_y': 286, 'depth': 127.15}]\n",
      "[{'bbox': [72, 94, 598, 479], 'conf': 0.88, 'class_name': 'person', 'center_x': 335, 'center_y': 286, 'depth': 127.15}]\n",
      "[{'bbox': [74, 72, 613, 479], 'conf': 0.88, 'class_name': 'person', 'center_x': 343, 'center_y': 275, 'depth': 127.81}]\n",
      "[{'bbox': [74, 70, 620, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 347, 'center_y': 274, 'depth': 127.67}]\n",
      "[{'bbox': [74, 70, 620, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 347, 'center_y': 274, 'depth': 127.67}]\n",
      "[{'bbox': [72, 72, 617, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 344, 'center_y': 275, 'depth': 127.72}]\n",
      "[{'bbox': [72, 66, 616, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 344, 'center_y': 272, 'depth': 127.44}]\n",
      "[{'bbox': [68, 76, 615, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 341, 'center_y': 277, 'depth': 127.94}]\n",
      "[{'bbox': [68, 76, 615, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 341, 'center_y': 277, 'depth': 127.94}]\n",
      "[{'bbox': [62, 71, 628, 479], 'conf': 0.89, 'class_name': 'person', 'center_x': 345, 'center_y': 275, 'depth': 127.87}]\n",
      "[{'bbox': [62, 77, 626, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 344, 'center_y': 278, 'depth': 127.8}]\n",
      "[{'bbox': [61, 77, 629, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 345, 'center_y': 278, 'depth': 127.61}]\n",
      "[{'bbox': [61, 77, 629, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 345, 'center_y': 278, 'depth': 127.61}]\n",
      "[{'bbox': [63, 70, 628, 479], 'conf': 0.89, 'class_name': 'person', 'center_x': 345, 'center_y': 274, 'depth': 127.67}]\n",
      "[{'bbox': [57, 67, 630, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 343, 'center_y': 273, 'depth': 128.73}]\n",
      "[{'bbox': [57, 67, 630, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 343, 'center_y': 273, 'depth': 128.73}]\n",
      "[{'bbox': [54, 72, 622, 479], 'conf': 0.89, 'class_name': 'person', 'center_x': 338, 'center_y': 275, 'depth': 126.97}]\n",
      "[{'bbox': [51, 74, 622, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 336, 'center_y': 276, 'depth': 127.36}]\n",
      "[{'bbox': [47, 72, 618, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 332, 'center_y': 275, 'depth': 127.54}]\n",
      "[{'bbox': [49, 78, 610, 479], 'conf': 0.89, 'class_name': 'person', 'center_x': 329, 'center_y': 278, 'depth': 127.16}]\n",
      "[{'bbox': [46, 80, 614, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 330, 'center_y': 279, 'depth': 127.47}]\n",
      "[{'bbox': [47, 77, 606, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 326, 'center_y': 278, 'depth': 127.08}]\n",
      "[{'bbox': [49, 76, 608, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 328, 'center_y': 277, 'depth': 127.12}]\n",
      "[{'bbox': [49, 76, 608, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 328, 'center_y': 277, 'depth': 127.12}]\n",
      "[{'bbox': [44, 76, 602, 479], 'conf': 0.91, 'class_name': 'person', 'center_x': 323, 'center_y': 277, 'depth': 127.06}]\n",
      "[{'bbox': [44, 76, 602, 479], 'conf': 0.91, 'class_name': 'person', 'center_x': 323, 'center_y': 277, 'depth': 127.06}]\n",
      "[{'bbox': [47, 79, 613, 479], 'conf': 0.91, 'class_name': 'person', 'center_x': 330, 'center_y': 279, 'depth': 127.49}]\n",
      "[{'bbox': [47, 79, 609, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 328, 'center_y': 279, 'depth': 126.8}]\n",
      "[{'bbox': [47, 79, 609, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 328, 'center_y': 279, 'depth': 126.8}]\n",
      "[{'bbox': [45, 76, 608, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 326, 'center_y': 277, 'depth': 128.32}]\n",
      "[{'bbox': [45, 74, 603, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 324, 'center_y': 276, 'depth': 127.17}]\n",
      "[{'bbox': [45, 74, 603, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 324, 'center_y': 276, 'depth': 127.17}]\n",
      "[{'bbox': [46, 73, 605, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 325, 'center_y': 276, 'depth': 126.64}]\n",
      "[{'bbox': [46, 73, 605, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 325, 'center_y': 276, 'depth': 126.64}]\n",
      "[{'bbox': [48, 75, 606, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 327, 'center_y': 277, 'depth': 128.23}]\n",
      "[{'bbox': [48, 75, 606, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 327, 'center_y': 277, 'depth': 128.23}]\n",
      "[{'bbox': [47, 78, 603, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 325, 'center_y': 278, 'depth': 128.13}]\n",
      "[{'bbox': [47, 78, 603, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 325, 'center_y': 278, 'depth': 128.13}]\n",
      "[{'bbox': [47, 78, 600, 479], 'conf': 0.89, 'class_name': 'person', 'center_x': 323, 'center_y': 278, 'depth': 127.47}]\n",
      "[{'bbox': [47, 75, 607, 479], 'conf': 0.89, 'class_name': 'person', 'center_x': 327, 'center_y': 277, 'depth': 128.09}]\n",
      "[{'bbox': [47, 75, 607, 479], 'conf': 0.89, 'class_name': 'person', 'center_x': 327, 'center_y': 277, 'depth': 128.09}]\n",
      "[{'bbox': [47, 78, 608, 479], 'conf': 0.89, 'class_name': 'person', 'center_x': 327, 'center_y': 278, 'depth': 126.25}]\n",
      "[{'bbox': [50, 74, 610, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 330, 'center_y': 276, 'depth': 127.18}]\n",
      "[{'bbox': [50, 74, 610, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 330, 'center_y': 276, 'depth': 127.18}]\n",
      "[{'bbox': [50, 75, 612, 479], 'conf': 0.9, 'class_name': 'person', 'center_x': 331, 'center_y': 277, 'depth': 127.49}]\n"
     ]
    }
   ],
   "source": [
    "# 파이썬 기본 패키지\n",
    "import threading\n",
    "import time\n",
    "from copy import deepcopy\n",
    "\n",
    "# 추가 설치 패키지\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "'''\n",
    "필요 기능:\n",
    "- 입력: cv2_bgr_image, depth_map\n",
    "- 출력: 감지 되었는지 return value, 사물 정보 dic_list: [{'class_name':person, 'conf':0.5, ''}]\n",
    "\n",
    "함수 인수 정보\n",
    "__init__.: YOLOv8 모델 버전\n",
    "detect: conf_thresh=0.65, class_filter=None, narmalized=True\n",
    "draw: 안에 있는 self.img랑 self.dic_list로 그린다\n",
    "'''\n",
    "\n",
    "\n",
    "class Custom_YOLOv8:\n",
    "    def __init__(self, model_name='yolov8n.pt', filter=None):\n",
    "        '''\n",
    "        입력되는 Image와 Depth Map에서 사물인식하여, 감지된 사물의 결과의 x, y, depth 정보를 반환\n",
    "        \n",
    "        model_name : YOLOv8 model 이름 입력(yolov8n.pt, yolov8s.pt, yolov8m.pt, yolov8l.pt, yolov8x.pt, 혹은 custom model 입력)\n",
    "        filter : 감지를 원하는 특정 사물이 있을 경우 list형태로 입력. None일 경우 모두 추론(None or ['person', 'cat'])\n",
    "        '''\n",
    "        print('자세한 기능 사용법 안내: https://github.com/Nyan-SouthKorea/YOLOv8_for_ROS2')\n",
    "        self._check_cuda()\n",
    "        self.model = YOLO(model_name)\n",
    "        self.filter = filter\n",
    "        self.img = None\n",
    "        self.depth_map = None\n",
    "        self.dic_list = []\n",
    "        self.run_request = False\n",
    "        self.thread = threading.Thread(target = self._prediction_thread)\n",
    "        self.thread.start()\n",
    "\n",
    "\n",
    "    def run(self, img, depth_map, conf_thresh=0.65):\n",
    "        '''\n",
    "        추론하기 원하는 image와 depth_map을 입력.\n",
    "        class 내부에서 multi-thread로 구동되는 YOLOv8 모델에 img와 depth_map을 업데이트하고 지금까지 처리된 가장 최근의 추론 결과를 반환.\n",
    "        (이렇게 처리하는 이유는, 성능이 낮은 컴퓨터에서도 렉이 걸리지 않게끔 보이기 위해서임)\n",
    "        \n",
    "        img : cv2로 처리할 수 있는 numpy 배열의 bgr 이미지\n",
    "        depth_map : numpy 배열의 2차원 1채널 거리 정보(안에 숫자들은 int, float 상관 없음)\n",
    "        conf_thresh : confidence threshold 설정\n",
    "        '''\n",
    "        # 처리해야 하는 img, depth_map 업데이트\n",
    "        self.img = img\n",
    "        self.depth_map = depth_map\n",
    "        self.conf_thresh = conf_thresh\n",
    "        self.run_request = True\n",
    "        \n",
    "        # 가장 최근까지 처리된 추론 결과 반환\n",
    "        if self.dic_list == []:\n",
    "            return_value = False\n",
    "        else:\n",
    "            return_value = True\n",
    "        return return_value, self.dic_list\n",
    "    \n",
    "    def draw(self):\n",
    "        '''\n",
    "        내부 변수 self.img와 self.dic_list를 활용하여 그려서 결과 반환\n",
    "        '''\n",
    "        img = deepcopy(self.img)\n",
    "        dic_list = deepcopy(self.dic_list)\n",
    "        for dic in self.dic_list:\n",
    "            cv2.rectangle(img, (dic['bbox'][0], dic['bbox'][1]), (dic['bbox'][2], dic['bbox'][3]), (0,0,255), 2)\n",
    "            text = f'{dic[\"class_name\"]}:{round(dic[\"conf\"], 2)}, depth: {dic[\"depth\"]}'\n",
    "            cv2.putText(img, text, (dic['bbox'][0], dic['bbox'][1]+25), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "        return img\n",
    "\n",
    "\n",
    "    def _prediction_thread(self):\n",
    "        '''\n",
    "        run 함수에서 업데이트된 self.img와 self.depth_map을 multi-thread로 처리하여 추론 결과를 self.dic_list에 업데이트 함\n",
    "        '''\n",
    "        class_list = None\n",
    "        while True:\n",
    "            # run()에서 이미지를 투입할 때 마다 구동\n",
    "            if self.run_request == False:\n",
    "                time.sleep(0.01)\n",
    "                continue\n",
    "            self.run_request = False\n",
    "\n",
    "            # run()에서 투입된 정보가 로직이 실행되는 중간에 섞이지 않도록 내부 함수로 업데이트\n",
    "            img = deepcopy(self.img)\n",
    "            depth_map = deepcopy(self.depth_map)\n",
    "            conf_thresh = deepcopy(self.conf_thresh)\n",
    "\n",
    "            # 추론\n",
    "            results = self.model.predict(source = cv2.cvtColor(img, cv2.COLOR_BGR2RGB), verbose = False)[0]\n",
    "            if class_list == None:\n",
    "                class_list = results.names\n",
    "            results = results.boxes.data.tolist()\n",
    "            dic_list = []\n",
    "            for result in results:\n",
    "                x1, y1, x2, y2, conf, cls = int(result[0]), int(result[1]), int(result[2]), int(result[3]), round(float(result[4]), 2), int(result[5])\n",
    "                class_name = class_list[cls] # class이름 추출\n",
    "                # conf_thresh 넘는 경우만 계산\n",
    "                if conf < conf_thresh:\n",
    "                    continue\n",
    "\n",
    "                # 만약 filter를 설정해 놓았을 경우, 원하는 class만 감지하기\n",
    "                if self.filter != None:\n",
    "                    if not class_name in self.filter:\n",
    "                        continue\n",
    "\n",
    "                # 감지된 사물의 x, y 포인트 계산\n",
    "                center_x = int((x2+x1)/2)\n",
    "                center_y = int((y2+y1)/2)\n",
    "                # depth 계산\n",
    "                depth = self._get_depth(depth_map, [x1,y1,x2,y2]) # depth 추출\n",
    "                dic_list.append({'bbox':[x1, y1, x2, y2], 'conf':conf, \n",
    "                                 'class_name':class_name, 'center_x':center_x, 'center_y':center_y, 'depth':depth})\n",
    "            # 실시간 추론값 업데이트\n",
    "            self.dic_list = deepcopy(dic_list)\n",
    "\n",
    "    def _get_depth(self, depth_map, bbox, rate=0.3):\n",
    "        '''\n",
    "        depth_map에서 bbox영역의 중앙 영역 depth를 반환\n",
    "\n",
    "        depth_map : 내부 변수\n",
    "        bbox : 내부 변수\n",
    "        rate : bbox 면적에서 해당 rate만큼의 중앙 영역의 평균 값을 계산함\n",
    "        '''\n",
    "        # rate 반영한 bbox 계산\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        # bbox의 가로 세로 길이\n",
    "        x_len = x2-x1\n",
    "        y_len = y2-y1\n",
    "        # rate 반영한 bbox의 가로 세로 길이\n",
    "        new_x_len = x_len*rate\n",
    "        new_y_len = y_len*rate\n",
    "        # rate 반영된 bbox 수치 계산\n",
    "        new_x1 = x1 + ((x_len-new_x_len)/2)\n",
    "        new_y1 = y1 + ((y_len-new_y_len)/2)\n",
    "        new_x2 = x2 - ((x_len-new_x_len)/2)\n",
    "        new_y2 = y2 - ((y_len-new_y_len)/2)\n",
    "        new_x1, new_y1, new_x2, new_y2 = int(new_x1), int(new_y1), int(new_x2), int(new_y2)\n",
    "        # depth_map에서 원하는 부분 crop하여 평균 depth 구하기\n",
    "        crop_depth = depth_map[new_y1:new_y2, new_x1:new_x2]\n",
    "        mean_depth = np.mean(crop_depth)\n",
    "        return round(mean_depth, 2)\n",
    "    \n",
    "    def _check_cuda(self):\n",
    "        '''\n",
    "        현재 설치된 torch 환경이 YOLO를 GPU에서 구동할 수 있는 환경인지 검사\n",
    "        '''\n",
    "        if torch.cuda.is_available():\n",
    "            print('GPU 사용 가능')\n",
    "        else:\n",
    "            print('GPU 사용 불가. CPU를 통한 추론만 가능')\n",
    "        \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    custom_YOLOv8 = Custom_YOLOv8(model_name='yolov8n.pt', filter=['person'])\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    while True:\n",
    "        # 웹캠 수신\n",
    "        ret, img = cap.read()\n",
    "        if ret == False:\n",
    "            print('웹캠 수신 안됨')\n",
    "            break\n",
    "        \n",
    "        # 더미 depth파일 생성\n",
    "        h, w, c = img.shape\n",
    "        depth_map = np.random.randint(0, 256, (w, h), dtype=np.uint8)\n",
    "\n",
    "        # 인퍼런스\n",
    "        ret, dic_list = custom_YOLOv8.run(img, depth_map)\n",
    "        if ret:\n",
    "            print(dic_list)\n",
    "        draw_img = custom_YOLOv8.draw()\n",
    "        \n",
    "        cv2.imshow('test', draw_img)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
