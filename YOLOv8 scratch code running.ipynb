{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현재 환경에서 YOLOv8을 GPU로 추론할 수 있는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 사용 가능\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print('GPU 사용 가능')\n",
    "else:\n",
    "    print('GPU 사용 불가. CPU를 통한 추론만 가능')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "필요 기능:\n",
    "- 입력: cv2_bgr_image, depth_map\n",
    "- 출력: 감지 되었는지 return value, 사물 정보 dic_list: [{'class_name':person, 'conf':0.5, ''}]\n",
    "\n",
    "함수 인수 정보\n",
    "__init__.: YOLOv8 모델 버전\n",
    "detect: conf_thresh=0.65, class_filter=None, narmalized=True\n",
    "draw: 안에 있는 self.img랑 self.dic_list로 그린다\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이썬 기본 패키지\n",
    "import threading\n",
    "import time\n",
    "from copy import deepcopy\n",
    "\n",
    "# 추가 설치 패키지\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "class Custom_YOLOv8:\n",
    "    def __init__(self, model_name='yolov8n.pt', filter=None):\n",
    "        '''\n",
    "        입력되는 Image와 Depth Map에서 사물인식하여, 감지된 사물의 결과의 x, y, depth 정보를 반환\n",
    "        \n",
    "        model_name : YOLOv8 model 이름 입력(yolov8n.pt, yolov8s.pt, yolov8m.pt, yolov8l.pt, yolov8x.pt, 혹은 custom model 입력)\n",
    "        filter : 감지를 원하는 특정 사물이 있을 경우 list형태로 입력. None일 경우 모두 추론(None or ['person', 'cat'])\n",
    "        '''\n",
    "        print('자세한 기능 사용법 안내: https://github.com/Nyan-SouthKorea/YOLOv8_for_ROS2')\n",
    "        self._check_cuda()\n",
    "        self.model = YOLO(model_name)\n",
    "        self.filter = filter\n",
    "        self.img = None\n",
    "        self.depth_map = None\n",
    "        self.dic_list = []\n",
    "        self.run_request = False\n",
    "        self.thread = threading.Thread(target = self._prediction_thread)\n",
    "        self.thread.start()\n",
    "\n",
    "\n",
    "    def run(self, img, depth_map, conf_thresh=0.65):\n",
    "        '''\n",
    "        추론하기 원하는 image와 depth_map을 입력.\n",
    "        class 내부에서 multi-thread로 구동되는 YOLOv8 모델에 img와 depth_map을 업데이트하고 지금까지 처리된 가장 최근의 추론 결과를 반환.\n",
    "        (이렇게 처리하는 이유는, 성능이 낮은 컴퓨터에서도 렉이 걸리지 않게끔 보이기 위해서임)\n",
    "        \n",
    "        img : cv2로 처리할 수 있는 numpy 배열의 bgr 이미지\n",
    "        depth_map : numpy 배열의 2차원 1채널 거리 정보(안에 숫자들은 int, float 상관 없음)\n",
    "        conf_thresh : confidence threshold 설정\n",
    "        '''\n",
    "        # 처리해야 하는 img, depth_map 업데이트\n",
    "        self.img = img\n",
    "        self.depth_map = depth_map\n",
    "        self.conf_thresh = conf_thresh\n",
    "        self.run_request = True\n",
    "        \n",
    "        # 가장 최근까지 처리된 추론 결과 반환\n",
    "        if self.dic_list == []:\n",
    "            return_value = False\n",
    "        else:\n",
    "            return_value = True\n",
    "        return return_value, self.dic_list\n",
    "    \n",
    "    def draw(self):\n",
    "        '''\n",
    "        내부 변수 self.img와 self.dic_list를 활용하여 그려서 결과 반환\n",
    "        '''\n",
    "        img = deepcopy(self.img)\n",
    "        dic_list = deepcopy(self.dic_list)\n",
    "        for dic in self.dic_list:\n",
    "            cv2.rectangle(img, (dic['bbox'][0], dic['bbox'][1]), (dic['bbox'][2], dic['bbox'][3]), (0,0,255), 2)\n",
    "            text = f'{dic[\"class_name\"]}:{round(dic[\"conf\"], 2)}, depth: {dic[\"depth\"]}'\n",
    "            cv2.putText(img, text, (dic['bbox'][0], dic['bbox'][1]+25), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "        return img\n",
    "\n",
    "\n",
    "    def _prediction_thread(self):\n",
    "        '''\n",
    "        run 함수에서 업데이트된 self.img와 self.depth_map을 multi-thread로 처리하여 추론 결과를 self.dic_list에 업데이트 함\n",
    "        '''\n",
    "        class_list = None\n",
    "        while True:\n",
    "            # run()에서 이미지를 투입할 때 마다 구동\n",
    "            if self.run_request == False:\n",
    "                time.sleep(0.01)\n",
    "                continue\n",
    "            self.run_request = False\n",
    "\n",
    "            # run()에서 투입된 정보가 로직이 실행되는 중간에 섞이지 않도록 내부 함수로 업데이트\n",
    "            img = deepcopy(self.img)\n",
    "            depth_map = deepcopy(self.depth_map)\n",
    "            conf_thresh = deepcopy(self.conf_thresh)\n",
    "\n",
    "            # 추론\n",
    "            results = self.model.predict(source = cv2.cvtColor(img, cv2.COLOR_BGR2RGB), verbose = False)[0]\n",
    "            if class_list == None:\n",
    "                class_list = results.names\n",
    "            results = results.boxes.data.tolist()\n",
    "            dic_list = []\n",
    "            for result in results:\n",
    "                x1, y1, x2, y2, conf, cls = int(result[0]), int(result[1]), int(result[2]), int(result[3]), round(float(result[4]), 2), int(result[5])\n",
    "                class_name = class_list[cls] # class이름 추출\n",
    "                # conf_thresh 넘는 경우만 계산\n",
    "                if conf < conf_thresh:\n",
    "                    continue\n",
    "\n",
    "                # 만약 filter를 설정해 놓았을 경우, 원하는 class만 감지하기\n",
    "                if self.filter != None:\n",
    "                    if not class_name in self.filter:\n",
    "                        continue\n",
    "\n",
    "                # 감지된 사물의 x, y 포인트 계산\n",
    "                center_x = int((x2+x1)/2)\n",
    "                center_y = int((y2+y1)/2)\n",
    "                # depth 계산\n",
    "                depth = self._get_depth(depth_map, [x1,y1,x2,y2]) # depth 추출\n",
    "                dic_list.append({'bbox':[x1, y1, x2, y2], 'conf':conf, \n",
    "                                 'class_name':class_name, 'center_x':center_x, 'center_y':center_y, 'depth':depth})\n",
    "            # 실시간 추론값 업데이트\n",
    "            self.dic_list = deepcopy(dic_list)\n",
    "\n",
    "    def _get_depth(self, depth_map, bbox, rate=0.3):\n",
    "        '''\n",
    "        depth_map에서 bbox영역의 중앙 영역 depth를 반환\n",
    "\n",
    "        depth_map : 내부 변수\n",
    "        bbox : 내부 변수\n",
    "        rate : bbox 면적에서 해당 rate만큼의 중앙 영역의 평균 값을 계산함\n",
    "        '''\n",
    "        # rate 반영한 bbox 계산\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        # bbox의 가로 세로 길이\n",
    "        x_len = x2-x1\n",
    "        y_len = y2-y1\n",
    "        # rate 반영한 bbox의 가로 세로 길이\n",
    "        new_x_len = x_len*rate\n",
    "        new_y_len = y_len*rate\n",
    "        # rate 반영된 bbox 수치 계산\n",
    "        new_x1 = x1 + ((x_len-new_x_len)/2)\n",
    "        new_y1 = y1 + ((y_len-new_y_len)/2)\n",
    "        new_x2 = x2 - ((x_len-new_x_len)/2)\n",
    "        new_y2 = y2 - ((y_len-new_y_len)/2)\n",
    "        new_x1, new_y1, new_x2, new_y2 = int(new_x1), int(new_y1), int(new_x2), int(new_y2)\n",
    "        # depth_map에서 원하는 부분 crop하여 평균 depth 구하기\n",
    "        crop_depth = depth_map[new_y1:new_y2, new_x1:new_x2]\n",
    "        mean_depth = np.mean(crop_depth)\n",
    "        return round(mean_depth, 2)\n",
    "    \n",
    "    def _check_cuda(self):\n",
    "        '''\n",
    "        현재 설치된 torch 환경이 YOLO를 GPU에서 구동할 수 있는 환경인지 검사\n",
    "        '''\n",
    "        if torch.cuda.is_available():\n",
    "            print('GPU 사용 가능')\n",
    "        else:\n",
    "            print('GPU 사용 불가. CPU를 통한 추론만 가능')\n",
    "        \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    custom_YOLOv8 = Custom_YOLOv8(model_name='yolov8n.pt', filter=['person'])\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    while True:\n",
    "        # 웹캠 수신\n",
    "        ret, img = cap.read()\n",
    "        if ret == False:\n",
    "            print('웹캠 수신 안됨')\n",
    "            break\n",
    "        \n",
    "        # 더미 depth파일 생성\n",
    "        h, w, c = img.shape\n",
    "        depth_map = np.random.randint(0, 256, (w, h), dtype=np.uint8)\n",
    "\n",
    "        # 인퍼런스\n",
    "        ret, dic_list = custom_YOLOv8.run(img, depth_map)\n",
    "        if ret:\n",
    "            print(dic_list)\n",
    "        else:\n",
    "            print('감지 내역 없음')\n",
    "        draw_img = custom_YOLOv8.draw()\n",
    "        \n",
    "        cv2.imshow('test', draw_img)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_map = np.random.randint(0, 256, (640, 480), dtype=np.uint8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
